{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822aeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "06/06/25\n",
    "for now this is a notebook, but if the plan is to automate,\n",
    "it will become a .py file that can be executed by terminal\n",
    "'''\n",
    "\n",
    "# NB - HAS TROUBLE WRITING TO ONEDRIVE\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display, clear_output\n",
    "\n",
    "\n",
    "def show_frame(frame):\n",
    "    '''sort of obsolete. function to show video inline. but prefered \n",
    "    method is just writing a new video mp4.'''\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca854ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(p1, p2):\n",
    "    '''gets midpoint from two pairs of coords'''\n",
    "    midp = np.array([(p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2])\n",
    "    return midp\n",
    "\n",
    "\n",
    "def get_COR(p1a, p2a, p1b, p2b, frame):\n",
    "    '''1 and 2 refer to endpoints, a and b refer to times. '''\n",
    "    # v1 and v2 are vectors between the two timelapses.\n",
    "    v1 = p1b - p1a\n",
    "    v2 = p2b - p2a\n",
    "\n",
    "    # calculate the vector midpoint \n",
    "    m1 = midpoint(p1a, p1b)\n",
    "    m2 = midpoint(p2a, p2b)\n",
    "    \n",
    "    # perpendicular bisector lines\n",
    "    n1 = np.array([-v1[1], v1[0]])\n",
    "    n2 = np.array([-v2[1], v2[0]])\n",
    "\n",
    "    # builds matrix to solve linalg equation, form b = A @ x\n",
    "    A = np.stack([n1, -n2], axis=1)\n",
    "    b = m2 - m1\n",
    "    \n",
    "    # see lab book\n",
    "    t = np.linalg.solve(A, b)\n",
    "    centre = m1 + t[0] * n1\n",
    "\n",
    "    # NEEDS TO BE INT FOR PLOTTING\n",
    "    m1 = [int(m1[0]), int(m1[1])]\n",
    "    m2 = [int(m2[0]), int(m2[1])]\n",
    "\n",
    "    # How far to extend the perpendicular line\n",
    "    scale_factor = 150 \n",
    "    \n",
    "    # For the first perpendicular bisector\n",
    "    pt1pos = (\n",
    "        m1[0] + int(n1[0] * scale_factor / np.linalg.norm(n1)),\n",
    "        m1[1] + int(n1[1] * scale_factor / np.linalg.norm(n1))\n",
    "    )\n",
    "    pt1neg = (\n",
    "        m1[0] - int(n1[0] * scale_factor / np.linalg.norm(n1)),\n",
    "        m1[1] - int(n1[1] * scale_factor / np.linalg.norm(n1))\n",
    "    )\n",
    "    \n",
    "    # For the second perpendicular bisector\n",
    "    pt2pos = (\n",
    "        m2[0] + int(n2[0] * scale_factor / np.linalg.norm(n2)),\n",
    "        m2[1] + int(n2[1] * scale_factor / np.linalg.norm(n2))\n",
    "    )\n",
    "    pt2neg = (\n",
    "        m2[0] - int(n2[0] * scale_factor / np.linalg.norm(n2)),\n",
    "        m2[1] - int(n2[1] * scale_factor / np.linalg.norm(n2))\n",
    "    )\n",
    "    \n",
    "    # draw line 1\n",
    "    cv2.line(frame, pt1pos, pt1neg, (255, 0, 0), 1)\n",
    "    cv2.line(frame, pt2pos, pt2neg, (255, 0, 0), 1)\n",
    "    \n",
    "    # Draw from midpoint to extended points\n",
    "    cv2.line(frame, m1, pt1pos, (255, 0, 0), 1)\n",
    "    cv2.line(frame, m1, pt1neg, (255, 0, 0), 1)\n",
    "    \n",
    "    return (int(centre[0]), int(centre[1]))\n",
    "\n",
    "\n",
    "def main_COR(inpath, outpath, skip_frame=1, start_time=0, validate=False):\n",
    "    '''input: file to analyse, output: path to analysed video. optional:\n",
    "    number of frames to skip to get centre, seconds of video to skip.'''\n",
    "    # loading input\n",
    "    cap = cv2.VideoCapture(inpath)\n",
    "    \n",
    "    # matches the new video to the old video specifications\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # skips ahead ||| MAKE SURE PROBE IS VISIBLE FROM THE FILM START ||| big obstacle for automation\n",
    "    start_frame = int(start_time * fps)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    # saving output to mp4 format\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_out = cv2.VideoWriter(outpath, fourcc, fps, (width, height))\n",
    "    if not video_out.isOpened():\n",
    "        print(\"main_COR: VideoWriter failed to open.\")\n",
    "        return  # exits function\n",
    "\n",
    "    # needed for rotational speed calc\n",
    "    frame_info = []\n",
    "    rot_list = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # end of video\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # filtering for red and then using \n",
    "        mask = colour_mask(frame, colour='red')\n",
    "        p1, p2 = detect_line(mask)\n",
    "        \n",
    "        if p1 and p2 is not None:\n",
    "            p1 = np.array(p1)\n",
    "            p2 = np.array(p2)\n",
    "\n",
    "            # just for tracking really not needed\n",
    "            mid = midpoint(p1, p2)\n",
    "\n",
    "            # storing this info for use in next part\n",
    "            frame_info.append((frame_count, p1, p2))\n",
    "            \n",
    "# ============ COMPARING WITH PREVIOUS FRAMES TO FIND COR ==========\n",
    "# A and B refer to time, 1 and 2 to endpoints again\n",
    "            if len(frame_info) >= skip_frame + 1:\n",
    "                # takes the info stored in the frame one skip ago\n",
    "                frameA_count, frameA_1, frameA_2 = \\\n",
    "                    frame_info[-(skip_frame + 1)]\n",
    "                \n",
    "                # compares to last frame\n",
    "                frameB_count, frameB_1, frameB_2 = \\\n",
    "                    frame_info[-1]\n",
    "\n",
    "                # p1a, p2a, p1b, p2b\n",
    "                centre = get_COR(frameA_1, frameA_2, frameB_1, frameB_2, frame)\n",
    "\n",
    "                if centre is not None:\n",
    "                    rot_list.append(centre)\n",
    "\n",
    "# cv2.circle(img, centre, radius, colour, thickness=-1 fills it)\n",
    "# cv2.line(frame, p1, p2, (RGB), thickness)\n",
    "                    # drawing previous line (darker red)\n",
    "                    cv2.line(frame, frameA_1, frameA_2, (0, 0, 165), 2)\n",
    "                    # midpoint\n",
    "                    cv2.circle(frame, tuple(mid.astype(int)), 4, \n",
    "                                (0, 225, 225), -1)\n",
    "                    # COR\n",
    "                    cv2.circle(frame, centre, 6,\n",
    "                                (0, 255, 0), 4)\n",
    "                    # mapping lines\n",
    "                    cv2.line(frame, frameA_1, frameB_1, (0, 255, 0), 1)\n",
    "                    cv2.line(frame, frameA_2, frameB_2, (0, 255, 0), 1)\n",
    "                    # perpendicular bisectors\n",
    "\n",
    "                else:\n",
    "                    print(\"get_COR returned None\")\n",
    "                    exit()\n",
    "                    \n",
    "            video_out.write(frame)\n",
    "\n",
    "            frame_count = frame_count + 1\n",
    "    \n",
    "    video_out.release()\n",
    "    print(f\"Video saved as {outpath}\")\n",
    "    \n",
    "    centres = np.array(rot_list)\n",
    "    try:\n",
    "        mean_COR = centres.mean(axis=0).astype(int)\n",
    "        print(\"Mean centre vs true centre = \",\n",
    "              (mean_COR[0] - centre[0]), (mean_COR[1] - centre[1]) )\n",
    "\n",
    "    except RuntimeWarning:\n",
    "        pass\n",
    "\n",
    "    if validate is True:\n",
    "        return centres\n",
    "    \n",
    "\n",
    "def colour_mask(frame, colour=\"red\"):\n",
    "    '''input: frame. returns: mask. Potential to have HSV lookup table\n",
    "    for different colours, but we will probably use red.'''\n",
    "    # threshold for red in HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    if colour == \"red\":\n",
    "        # red wraps round two bands of the HSV spectrum\n",
    "        lower_red1 = np.array([0, 100, 100])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160, 100, 100])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "        \n",
    "        # turns all pixels to black if not in the HSV red ranges\n",
    "        # and combines the two masks\n",
    "        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    elif colour == \"blue\":\n",
    "        # these HSV values work really well for the probe colour\n",
    "        lower_blue = np.array([100, 150, 100])  # H, S, V\n",
    "        upper_blue = np.array([130, 255, 255])\n",
    "        mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "def detect_line(mask):\n",
    "    '''input: mask. returns: tuple, tuple. If lines not none,\n",
    "    returns point 1 and 2 coords.'''\n",
    "    # canny removes noise with a 5x5 gaussian filter,\n",
    "    # converts a normal image into a sketch made up of lines only.\n",
    "    edges = cv2.Canny(mask, 50, 150)  # args min and max val - threshold for edge\n",
    "    \n",
    "    # line detection - Hough algorithm probabilistic\n",
    "    # OR with high contrast - use cv2.findNonZero() to directly fit a line\n",
    "    # w/ cv2.fitLine\n",
    "    # =======================================================\n",
    "    # HoughLines expresses line in polar coords. Intersections define points\n",
    "    # belonging to the same line. Threshold is min intersections to define line\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50,\n",
    "                            minLineLength=50, maxLineGap=10)\n",
    "\n",
    "# lines is an array([[[x1, y1, x2, y2]],\n",
    "#                    [[x1, y1, x2, y2]])\n",
    "# lines[0][0] is = line[0]\n",
    "\n",
    "    if lines is not None:\n",
    "        # finding the longest line and returning the end points\n",
    "        # again probably overkill for one line as long as the mask works\n",
    "        longest = None        \n",
    "        max_len = 0\n",
    "        for line in lines:\n",
    "        # line is lines[i] and line[0] just extracts [x1, y1, x2, y2]\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # length = np.hypot(x2 - x1, y2 - y1)\n",
    "            length = np.sqrt( (x2 - x1)**2 + (y2 - y1)**2)\n",
    "            if length > max_len:\n",
    "                max_len = length\n",
    "                longest = line[0]\n",
    "\n",
    "        if longest is not None:\n",
    "            x1, y1, x2, y2 = longest\n",
    "            return [x1, y1], [x2, y2]\n",
    "        \n",
    "    return None, None  # no lines found\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a52461",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def mask_check(inpath, outpath, start_time=0, colour='red'):\n",
    "    '''input: file to analyse, output: path to analysed video. video of mask.'''\n",
    "    # loading input\n",
    "    cap = cv2.VideoCapture(inpath)\n",
    "    \n",
    "    # matches the new video to the old video specifications\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # skips ahead ||| MAKE SURE PROBE IS VISIBLE FROM THE FILM START |||\n",
    "    start_frame = int(start_time * fps)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    # saving output to mp4 format\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_out = cv2.VideoWriter(outpath, fourcc, fps, (width, height))\n",
    "    if not video_out.isOpened():\n",
    "        print(\"mask_check: VideoWriter failed to open.\")\n",
    "        return\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # end of video\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # filtering for red and then using \n",
    "        mask = colour_mask(frame, colour=colour)\n",
    "\n",
    "        video_out.write(mask)\n",
    "\n",
    "    cap.release()\n",
    "    video_out.release()\n",
    "    print(f\"Video saved as {outpath}\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc5ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as C:\\Users\\rj429\\test_line_video.mp4\n",
      "Video saved as C:\\Users\\rj429\\result_1.mp4\n",
      "Mean centre vs true centre =  8 17\n"
     ]
    }
   ],
   "source": [
    "# input = \"M3B_EXTENDED_UR1_154519.mp4\"\n",
    "# # input = r\"C:\\Users\\rj429\\test_line_video.mp4\"\n",
    "# output = r\"C:\\Users\\rj429\\analysed_COR_video_blue.mp4\"\n",
    "\n",
    "input = r\"C:\\Users\\rj429\\test_line_video.mp4\"\n",
    "ifile = r\"C:\\Users\\rj429\\M1B_R1S_145621480.mp4\"\n",
    "# i = np.random.randint(1,100)\n",
    "# print(i)\n",
    "output = f\"C:\\\\Users\\\\rj429\\\\result_1.mp4\"\n",
    "# bool = test_data(input, amplitude=0)\n",
    "# mask_check(ifile, output, start_time=11)\n",
    "# test_data(input, centre=[205, 235], thickness=2, amplitude=0)\n",
    "main_COR(input, output, start_time=0)\n",
    "# validate(input, output, amplitude=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954a1b9-2262-4bc0-91ae-2a5b13ce60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image and convert to grayscale\n",
    "input = \"M3R2S_155427.mp4\"\n",
    "\n",
    "output = \"rectangle_test_vid.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Get frames per second\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "frames_to_show = []\n",
    "\n",
    "# saving output to mp4 format\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_out = cv2.VideoWriter(output, fourcc, fps, (width, height))\n",
    "if not video_out.isOpened():\n",
    "    print(\"mask_check: VideoWriter failed to open.\")\n",
    "    exit()\n",
    "\n",
    "# skips some time ahead to stable rotation\n",
    "start_time = 10\n",
    "end_time = 15\n",
    "start_frame = int(start_time * fps)\n",
    "end_frame = int(end_time * fps)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened() and frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    mask = colour_mask(frame)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Approximate contour to polygon\n",
    "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        # Filter polygons with 4 vertices (possible rectangles)\n",
    "        if len(approx) == 4:\n",
    "            # Check if polygon is convex\n",
    "            if cv2.isContourConvex(approx):\n",
    "                # Optionally: check aspect ratio and angles\n",
    "                # Extract points\n",
    "                pts = approx.reshape(4, 2)\n",
    "                cv2.drawContours(frame, [approx], -1, (0, 255, 0), 3)\n",
    "    \n",
    "\n",
    "                \n",
    "                \n",
    "                # # Compute aspect ratio\n",
    "                # (x, y, w, h) = cv2.boundingRect(approx)\n",
    "                # aspect_ratio = float(w) / h\n",
    "                \n",
    "                # # Check aspect ratio if you want rectangles not squares, e.g.:\n",
    "                # if 0.8 < aspect_ratio < 6:  # roughly square, adjust as needed\n",
    "                #     # Optional: check angles ~90 degrees\n",
    "                #     def angle(pt1, pt2, pt0):\n",
    "                #         dx1 = pt1[0] - pt0[0]\n",
    "                #         dy1 = pt1[1] - pt0[1]\n",
    "                #         dx2 = pt2[0] - pt0[0]\n",
    "                #         dy2 = pt2[1] - pt0[1]\n",
    "                #         return abs(np.arccos((dx1*dx2 + dy1*dy2) / \n",
    "                #                     (np.sqrt(dx1**2 + dy1**2) * np.sqrt(dx2**2 + dy2**2))) * 180 / np.pi)\n",
    "                    \n",
    "                #     angles = []\n",
    "                #     for i in range(4):\n",
    "                #         angles.append(angle(pts[i], pts[(i-2)%4], pts[(i-1)%4]))\n",
    "                #     if all(80 < a < 100 for a in angles):\n",
    "                #         cv2.drawContours(frame, [approx], -1, (0, 255, 0), 3)\n",
    "    \n",
    "    video_out.write(frame)\n",
    "    frame_count = frame_count + 1\n",
    "\n",
    "\n",
    "cap.release()\n",
    "video_out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ec7cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as rectangle_mask.mp4\n"
     ]
    }
   ],
   "source": [
    "mask_check(\"M1B_UR1S_145845345.mp4\", \"rectangle_mask.mp4\", start_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7b90ea-65ea-40e7-b97a-91f5d03cb0ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3754308949.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    def main()\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "video_in = \"M3R2S_155427.mp4\"\n",
    "\n",
    "\n",
    "def line_orientation(contour):\n",
    "    ''''''\n",
    "    data_pts = np.array(contour, dtype=np.float32).reshape(-1, 2)  #\n",
    "\n",
    "    # \n",
    "    mean, eigenvectors = cv2.PCACompute(data_pts, mean=None)\n",
    "\n",
    "    # eigenvectors doesn't always have the right shape. Possibly due to no contours found.\n",
    "    # but throws errors and stops code for any failure otherwise\n",
    "    if eigenvectors is not None and eigenvectors.shape[0] >= 1 and eigenvectors.shape[1] >= 2:\n",
    "        #\n",
    "        center = tuple(mean[0])\n",
    "        \n",
    "        # angle = arctan(y/x)\n",
    "        angle = np.arctan2(eigenvectors[0, 1], eigenvectors[0, 0])  # radians\n",
    "\n",
    "        return center, angle\n",
    "        \n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def main()\n",
    "cap = cv2.VideoCapture(video_in)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Get frames per second\n",
    "\n",
    "# skips some time ahead to stable rotation\n",
    "start_time = 10\n",
    "start_frame = int(start_time * fps)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "frames_to_show = []\n",
    "\n",
    "# initialised for appending values for each frame and counting frames\n",
    "angles = []\n",
    "timestamps = []\n",
    "frame_number = 0\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    LOWER_BLUE = np.array([100, 150, 100])  # H, S, V\n",
    "    UPPER_BLUE = np.array([130, 255, 255])\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # blue_mask = cv2.inRange(hsv, LOWER_BLUE, UPPER_BLUE)\n",
    "    mask = colour_mask(hsv)\n",
    "    \n",
    "#     plt.imshow(blue_mask, cmap='gray')  # Use gray colormap for binary masks\n",
    "#     plt.title(\"Blue Mask\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        largest = max(contours, key=cv2.contourArea)\n",
    "        center, angle_rad = get_orientation(largest)\n",
    "        if center is None or angle_rad is None:\n",
    "            continue  # Skip this frame\n",
    "        else:\n",
    "            angles.append(angle_rad)\n",
    "            timestamps.append((frame_number - start_frame) / fps)\n",
    "\n",
    "        # Convert center to int for drawing\n",
    "        center_int = tuple(map(int, center))\n",
    "\n",
    "        # defines endpoint of line that runs through the geometric centre\n",
    "        # found by contours\n",
    "        length = 150\n",
    "        x1 = int(center[0] - length/2 * np.cos(angle_rad))\n",
    "        y1 = int(center[1] - length/2 * np.sin(angle_rad))\n",
    "        x2 = int(center[0] + length/2 * np.cos(angle_rad))\n",
    "        y2 = int(center[1] + length/2 * np.sin(angle_rad))\n",
    "\n",
    "\n",
    "        # Draw the major axis line\n",
    "        cv2.line(frame, center_int, (x2, y2), (0, 255, 0), 2)  # green line\n",
    "\n",
    "        # Optionally draw the center point\n",
    "        cv2.circle(frame, center_int, 5, (0, 0, 255), -1)  # red dot\n",
    "        \n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frames_to_show.append(frame_rgb)\n",
    "\n",
    "    frame_number = frame_number + 1\n",
    "    \n",
    "\n",
    "angles = np.unwrap(angles)  # unwrap to avoid 360Â° jump\n",
    "angular_velocity = np.gradient(angles, timestamps)  # radians per second\n",
    "\n",
    "# Plot\n",
    "plt.plot(timestamps, angular_velocity)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Angular velocity (rad/s)')\n",
    "plt.title('Rotational Velocity Over Time')\n",
    "plt.show()\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# matplotlib to create HTML to watch video inline\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(frames_to_show[0])\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "def update(i):\n",
    "    im.set_array(frames_to_show[i])\n",
    "    return [im]\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(frames_to_show), interval=800 / fps, blit=True)\n",
    "\n",
    "HTML(ani.to_html5_video())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
